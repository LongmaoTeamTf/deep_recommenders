{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a578eb21eb1f0ffbce406cca18fb76957b43a943c95f6e1cf142c9c0a29ae48e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# DeepFM\n",
    "\n",
    "DeepFM: A Factorization-Machine based Neural Network for CTR Prediction\n",
    "\n",
    "https://arxiv.org/abs/1703.04247\n",
    "\n",
    "https://www.tensorflow.org/datasets/catalog/movielens\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.dont_write_bytecode = True\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from deep_recommenders import models as dprs_models\n",
    "from deep_recommenders import tasks as dprs_tasks\n",
    "from deep_recommenders import metrics as dprs_metrics\n",
    "from deep_recommenders.layers.fm import FM\n"
   ]
  },
  {
   "source": [
    "## 数据准备\n",
    "\n",
    "\n",
    "使用Movielens-100k作为训练数据，具体介绍可以参考\n",
    "\n",
    "https://www.tensorflow.org/datasets/catalog/movielens\n",
    "\n",
    "### 特征\n",
    "\n",
    "\n",
    "3个用户特征: \n",
    "* `user_id`\n",
    "* `user_gender`\n",
    "* `bucketized_user_age`\n",
    "* `user_occupation_label`\n",
    "\n",
    "2个电影特征，分别是：\n",
    "* `movie_id`\n",
    "* `movie_title`\n",
    "\n",
    "由于`user_rating`特征为1-5星评价，为了适用二分类任务，\n",
    "\n",
    "将大于3星的（即4星和5星）评价转化了`1.0`，将少于或等于3星的评价转化为`0.`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_gender\": tf.cast(x[\"user_gender\"], tf.int32),\n",
    "    \"bucketized_user_age\": tf.cast(x[\"bucketized_user_age\"], tf.int32),\n",
    "    \"user_occupation_label\": tf.cast(x[\"user_occupation_label\"], tf.int32),\n",
    "    \"movie_id\": x[\"movie_id\"],\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_rating\": tf.cond(x[\"user_rating\"] > 3, true_fn=lambda: 1.0, false_fn=lambda: 0.0)\n",
    "})\n",
    "unique_user_ids = np.unique(np.concatenate(list(ratings.batch(1_000).map(\n",
    "    lambda x: x[\"user_id\"]))))\n",
    "unique_user_ages = np.unique(np.concatenate(list(ratings.batch(1_000).map(\n",
    "    lambda x: x[\"bucketized_user_age\"]))))\n",
    "unique_user_occupation_labels = np.unique(np.concatenate(list(ratings.batch(1_000).map(\n",
    "    lambda x: x[\"user_occupation_label\"]))))\n",
    "unique_movie_ids = np.unique(np.concatenate(list(ratings.batch(1_000).map(\n",
    "    lambda x: x[\"movie_id\"]))))\n",
    "\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])\n"
   ]
  },
  {
   "source": [
    "## 模型构建\n",
    "\n",
    "### 构建embedding层\n",
    "\n",
    "注意：DeepFM模型即需要稠密的`Dense Embedding`用于`FM`的2-order交互和`DNN`的high-order交互.\n",
    "\n",
    "同时，也需要稀疏的`One-Hot Embedding`用于`FM`的1-order交互."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _vocab_list_embedding(key: str, vocab_list: list, embedding_dim: int):\n",
    "    \"\"\"Vocab list embedding\"\"\"\n",
    "    categorical_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        key, vocab_list)\n",
    "    \n",
    "    dense_embedding_layer = tf.keras.layers.DenseFeatures(\n",
    "        tf.feature_column.embedding_column(\n",
    "            categorical_col,\n",
    "            dimension=embedding_dim, \n",
    "            combiner=\"sum\"))\n",
    "\n",
    "    sparse_embedding_layer = tf.keras.layers.DenseFeatures(\n",
    "        tf.feature_column.indicator_column(categorical_col))\n",
    "    \n",
    "    return dense_embedding_layer, sparse_embedding_layer"
   ]
  },
  {
   "source": [
    "### 构建用户Embedding模型"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "    \"\"\"User Embedding Model\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.user_dense_embedding, self.user_sparse_embedding = _vocab_list_embedding(\n",
    "            \"user_id\", unique_user_ids, 32)\n",
    "        self.gender_dense_embedding, self.gender_sparse_embedding = _vocab_list_embedding(\n",
    "            \"user_gender\", [0, 1], 32)\n",
    "        self.age_dense_embedding, self.age_sparse_embedding = _vocab_list_embedding(\n",
    "            \"bucketized_user_age\", unique_user_ages, 32)\n",
    "        self.occupation_dense_embedding, self.occupation_sparse_embedding = _vocab_list_embedding(\n",
    "            \"user_occupation_label\", unique_user_occupation_labels, 32)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # 输入为字典类型\n",
    "        dense_embeddings = tf.stack([\n",
    "            self.user_dense_embedding({\"user_id\": inputs[\"user_id\"]}),\n",
    "            self.gender_dense_embedding({\"user_gender\": inputs[\"user_gender\"]}),\n",
    "            self.age_dense_embedding({\"bucketized_user_age\": inputs[\"bucketized_user_age\"]}),\n",
    "            self.occupation_dense_embedding({\"user_occupation_label\": inputs[\"user_occupation_label\"]})\n",
    "        ], axis=1)\n",
    "        sparse_embeddings = tf.concat([\n",
    "            self.user_sparse_embedding({\"user_id\": inputs[\"user_id\"]}),\n",
    "            self.gender_sparse_embedding({\"user_gender\": inputs[\"user_gender\"]}),\n",
    "            self.age_sparse_embedding({\"bucketized_user_age\": inputs[\"bucketized_user_age\"]}),\n",
    "            self.occupation_sparse_embedding({\"user_occupation_label\": inputs[\"user_occupation_label\"]})\n",
    "        ], axis=1)\n",
    "        return dense_embeddings, sparse_embeddings"
   ]
  },
  {
   "source": [
    "### 构建电影Embedding模型"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieModel(tf.keras.Model):\n",
    "    \"\"\"Movie Embedding Model\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.movie_dense_embedding, self.movie_sparse_embedding = _vocab_list_embedding(\n",
    "            \"movie_id\", unique_movie_ids, 32)\n",
    "        \n",
    "        max_tokens = 10_000\n",
    "\n",
    "        self.title_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "            max_tokens=max_tokens)\n",
    "\n",
    "        self.title_embedding = tf.keras.Sequential([\n",
    "            self.title_vectorizer,\n",
    "            tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
    "            tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        ])\n",
    "\n",
    "        self.title_vectorizer.adapt(movies)\n",
    "       \n",
    "    def call(self, inputs):\n",
    "        # 输入为字典类型\n",
    "        dense_embeddings = tf.stack([\n",
    "            self.movie_dense_embedding({\"movie_id\": inputs[\"movie_id\"]}),\n",
    "            self.title_embedding(inputs[\"movie_title\"]),\n",
    "        ], axis=1)\n",
    "        sparse_embeddings = self.movie_sparse_embedding(\n",
    "            {\"movie_id\": inputs[\"movie_id\"]})\n",
    "        return dense_embeddings, sparse_embeddings"
   ]
  },
  {
   "source": [
    "### 构建 DeepFM 模型"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFM(dprs_models.Model):\n",
    "    \"\"\"DeepFM model\"\"\"\n",
    "\n",
    "    def __init__(self, layer_sizes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.user_model = UserModel()\n",
    "        self.movie_model = MovieModel()\n",
    "\n",
    "        # 构建 linear\n",
    "        self.linear = tf.keras.layers.Dense(1)\n",
    "\n",
    "        # FM factor embedding 与 user_embedding, movie_embedding共享\n",
    "        self.fm = FM(factors=None)\n",
    "\n",
    "        # 构建 dnn layers\n",
    "        self.dnn = tf.keras.Sequential()\n",
    "\n",
    "        self.dnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "        for layer_size in layer_sizes:\n",
    "            self.dnn.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "        self.dnn.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "        # logit layer\n",
    "        self.logits_layer = tf.keras.Sequential([\n",
    "            tf.keras.layers.Add(),\n",
    "            tf.keras.layers.Activation(\"sigmoid\")\n",
    "        ])\n",
    "\n",
    "        self.task = dprs_tasks.Ranking(\n",
    "            metrics=[tf.keras.metrics.AUC(name=\"auc\")]\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "\n",
    "        user_dense_embeddings, user_sparse_embeddings = self.user_model({\n",
    "            \"user_id\": features[\"user_id\"],\n",
    "            \"user_gender\": features[\"user_gender\"],\n",
    "            \"bucketized_user_age\": features[\"bucketized_user_age\"],\n",
    "            \"user_occupation_label\": features[\"user_occupation_label\"],\n",
    "        })\n",
    "\n",
    "        movie_dense_embeddings, movie_sparse_embeddings = self.movie_model({\n",
    "            \"movie_id\": features[\"movie_id\"],\n",
    "            \"movie_title\": features[\"movie_title\"],\n",
    "        })\n",
    "\n",
    "        sparse_embeddings = tf.concat([user_sparse_embeddings, movie_sparse_embeddings], axis=1)\n",
    "        linear_outputs = self.linear(sparse_embeddings)\n",
    "\n",
    "        dense_embeddings = tf.concat([user_dense_embeddings, movie_dense_embeddings], axis=1)\n",
    "\n",
    "        fm_outputs = self.fm(dense_embeddings)\n",
    "        dnn_outputs = self.dnn(dense_embeddings)\n",
    "\n",
    "        logits = self.logits_layer(\n",
    "            [linear_outputs, fm_outputs, dnn_outputs]\n",
    "        )\n",
    "\n",
    "        return self.task(features[\"user_rating\"], logits)        "
   ]
  },
  {
   "source": [
    "## 数据shuffle和split\n",
    "\n",
    "Train: Test = 8: 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(2048)\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "source": [
    "## 模型训练"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "model = DeepFM([64, 32])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "history = model.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=5,\n",
    "    epochs=num_epochs,\n",
    "    verbose=0)\n",
    "\n",
    "accuracy = history.history[\"val_auc\"][-1]\n",
    "print(f\"val-auc accuracy: {accuracy:.2f}.\")"
   ]
  },
  {
   "source": [
    "## 可视化训练Metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in [\"auc\", \"loss\"]:\n",
    "    num_train_runs = len(history.history[metric])\n",
    "    train_epochs = [(x + 1) for x in range(num_train_runs)]\n",
    "\n",
    "    num_validation_runs = len(history.history[f\"val_{metric}\"])\n",
    "    test_epochs = [(x + 1)* 5 for x in range(num_validation_runs)]\n",
    "\n",
    "    plt.plot(train_epochs, history.history[metric], label=\"train\")\n",
    "    plt.plot(test_epochs, history.history[f\"val_{metric}\"], label=\"test\")\n",
    "    plt.title(f\"{metric} vs epoch\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(f\"{metric}\");\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(\"assets\", f\"deepfm_{metric}.png\"))\n",
    "    plt.show()"
   ]
  }
 ]
}